# -*- coding: utf-8 -*-
"""EXPONENTIAL SMOOTHING HOLT-WINTERS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k9mzzmjm3z62mM1h2lo8ZiPFmxCxUrTb
"""

import pandas as pd
import numpy as np
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.metrics import mean_absolute_error, mean_squared_error
from math import sqrt

data=pd.read_excel(r"C:\Users\Deepak Raj\OneDrive\Desktop\Spice price pred project\Spices_Final_Data(Mine_loc_without_grade)\Spices_Final_Data(Mine_loc_without_grade).xlsx")

data.isnull().sum()

# Replace null values in 'Price' column with the mean
data['Price'].fillna(data['Price'].mean(), inplace=True)

# Display the updated DataFrame
print(data)

data['Location'].unique()

# Replace 'cochiin' with 'cochin' in the 'Location' column
data['Location'] = data['Location'].replace('COCHIIN', 'COCHIN')

# Display the DataFrame after replacement
print(data)

data['Location'].unique()

data['Location'].fillna("Missing", inplace=True)


# Define the order of locations based on your criteria
location_order = {'CHENNAI': 1, 'COCHIN': 2, 'DELHI': 3, 'GANGTOK':4, 'Missing':5}

# Apply ordinal encoding to the 'Location' column
data['Location_encoded'] = data['Location'].map(location_order)

# Display the DataFrame after ordinal encoding
print(data[['Location', 'Location_encoded']])

# Drop the 'Location' column
data.drop('Location', axis=1, inplace=True)

from sklearn.preprocessing import LabelEncoder
# Create a LabelEncoder instance
label_encoder = LabelEncoder()

# Fit and transform the 'Location' column
data['Grade_encoded'] = label_encoder.fit_transform(data['Grade'])

# Display the updated DataFrame with the encoded 'Location' column
print(data[['Grade', 'Grade_encoded']])

print(data)

# Drop the 'Location' column
data.drop('Grade', axis=1, inplace=True)

# Replace 'df' with your actual DataFrame and 'Price' with the column name
lower_bound = data['Price'].quantile(0.25)  # Choose an appropriate lower quantile
upper_bound = data['Price'].quantile(0.75)  # Choose an appropriate upper quantile

data['Price'] = data['Price'].clip(lower=lower_bound, upper=upper_bound)

import seaborn as sns
sns.boxplot(data['Price'])
data.isnull().sum()

# Convert 'Month&Year' to datetime format
data['Month&Year'] = pd.to_datetime(data['Month&Year'], format='%b-%y')

def forecast_spice(data, spice, seasonal_periods):
    # Filter data for the specific spice
    spice_data = data[data['Spices'] == spice].set_index('Month&Year')

    # Split data into training and test sets
    train = spice_data[:-12]  # Use all but the last 12 months for training
    test = spice_data[-12:]  # Use the last 12 months for testing

    # Build and fit the model
    model = ExponentialSmoothing(train['Price'], trend='add', seasonal='add', seasonal_periods=seasonal_periods)
    model_fit = model.fit()

    # Make predictions
    predictions = model_fit.predict(start=len(train), end=len(train) + len(test) - 1)

    # Calculate RMSE and MAPE
    rmse = sqrt(mean_squared_error(test['Price'], predictions))
    mape = mean_absolute_percentage_error(test['Price'], predictions)

    return rmse, mape

from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error
for spice in spices:
    rmse, mape = forecast_spice(data, spice, seasonal_periods=6)  # Adjust the seasonal_periods parameter as needed
    print(f'Spice: {spice}, RMSE: {rmse}, MAPE: {mape}')



